{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 1: Import Required Libraries",
   "id": "558f1d88b2f3f33b"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-03T23:20:20.520158Z",
     "start_time": "2024-12-03T23:19:58.853704Z"
    }
   },
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import optuna\n",
    "import torch\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common.logger import configure\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 2: Define Environment",
   "id": "9c551dfcf6bb1875"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T23:20:20.643469Z",
     "start_time": "2024-12-03T23:20:20.617176Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "class IbuprofenEnv(gym.Env):\n",
    "    def __init__(self, normalize=False):\n",
    "        super(IbuprofenEnv, self).__init__()\n",
    "\n",
    "        # Define the action space and observation space\n",
    "        self.action_space = gym.spaces.Discrete(5)\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=100, shape=(1,), dtype=np.float32)\n",
    "\n",
    "        # Pharmacokinetics parameters\n",
    "        self.therapeutic_range = (10, 50)\n",
    "        self.half_life = 2.0\n",
    "        self.clearance_rate = 0.693 / self.half_life\n",
    "        self.time_step_hours = 1\n",
    "        self.bioavailability = 0.9\n",
    "        self.volume_of_distribution = 0.15\n",
    "        self.max_steps = 24\n",
    "        self.current_step = 0\n",
    "        self.plasma_concentration = 0.0\n",
    "        self.state_buffer = []\n",
    "        self.time_in_therapeutic_range = 0  # Track time in the therapeutic range\n",
    "        self.normalize = normalize\n",
    "\n",
    "    def reset(self, seed=None, **kwargs):\n",
    "        super().reset(seed=seed)\n",
    "        self.current_step = 0\n",
    "        self.plasma_concentration = 0.0\n",
    "        self.state_buffer = []\n",
    "        self.time_in_therapeutic_range = 0  # Reset the counter for each episode\n",
    "        state = np.array([self.plasma_concentration], dtype=np.float32)\n",
    "        return self._normalize(state), {}\n",
    "\n",
    "    def step(self, action):\n",
    "        dose_mg = action * 200\n",
    "        absorbed_mg = dose_mg * self.bioavailability\n",
    "        absorbed_concentration = absorbed_mg / (self.volume_of_distribution * 70)\n",
    "        self.plasma_concentration += absorbed_concentration\n",
    "        self.plasma_concentration *= np.exp(-self.clearance_rate * self.time_step_hours)\n",
    "\n",
    "        state = np.array([self.plasma_concentration], dtype=np.float32)\n",
    "        normalized_state = self._normalize(state)\n",
    "\n",
    "        self.state_buffer.append(self.plasma_concentration)\n",
    "\n",
    "        # Track time in therapeutic range\n",
    "        if self.therapeutic_range[0] <= self.plasma_concentration <= self.therapeutic_range[1]:\n",
    "            self.time_in_therapeutic_range += 1  # Increment if in the therapeutic range\n",
    "\n",
    "        # Reward shaping logic\n",
    "        if self.therapeutic_range[0] <= self.plasma_concentration <= self.therapeutic_range[1]:\n",
    "            reward = 10  # Positive reward for being in the therapeutic range\n",
    "        else:\n",
    "            if self.plasma_concentration < self.therapeutic_range[0]:\n",
    "                reward = -5 - (self.therapeutic_range[0] - self.plasma_concentration) * 0.5\n",
    "            elif self.plasma_concentration > self.therapeutic_range[1]:\n",
    "                reward = -5 - (self.plasma_concentration - self.therapeutic_range[1]) * 0.5\n",
    "\n",
    "        # Add a heavy penalty for toxic concentrations\n",
    "        if self.plasma_concentration > 100:\n",
    "            reward -= 15  # Severe penalty for toxic levels\n",
    "\n",
    "        self.current_step += 1\n",
    "        done = self.current_step >= self.max_steps\n",
    "        truncated = False  # For this environment, there's no specific truncation condition\n",
    "        info = {\"plasma_concentration\": self.plasma_concentration}  # Add plasma_concentration to the info dictionary\n",
    "\n",
    "        return normalized_state, reward, done, truncated, info\n",
    "\n",
    "    def _normalize(self, state):\n",
    "        if self.normalize and len(self.state_buffer) > 1:\n",
    "            mean = np.mean(self.state_buffer)\n",
    "            std = np.std(self.state_buffer) + 1e-8\n",
    "            return (state - mean) / std\n",
    "        return state\n",
    "\n",
    "\n"
   ],
   "id": "c54c0d1f2b046abd",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T23:20:20.790019Z",
     "start_time": "2024-12-03T23:20:20.782433Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class RewardLoggingCallback(BaseCallback):\n",
    "    def __init__(self):\n",
    "        super(RewardLoggingCallback, self).__init__()\n",
    "        self.episode_rewards = []\n",
    "        self.current_episode_reward = 0\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        # Accumulate reward for the current step\n",
    "        self.current_episode_reward += self.locals[\"rewards\"][0]\n",
    "\n",
    "        # If the episode ends, log the reward\n",
    "        if self.locals[\"dones\"][0]:\n",
    "            self.episode_rewards.append(self.current_episode_reward)\n",
    "            self.current_episode_reward = 0  # Reset for the next episode\n",
    "        return True"
   ],
   "id": "8269d87076eae8f1",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T23:20:20.909784Z",
     "start_time": "2024-12-03T23:20:20.901826Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CustomLoggingCallback(BaseCallback):\n",
    "    def __init__(self, writer, log_interval=10):\n",
    "        super(CustomLoggingCallback, self).__init__()\n",
    "        self.writer = writer\n",
    "        self.log_interval = log_interval\n",
    "        self.episode_rewards = []\n",
    "        self.current_episode_reward = 0\n",
    "        self.time_in_therapeutic_range = 0\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        # Track rewards per episode\n",
    "        self.current_episode_reward += self.locals[\"rewards\"][0]\n",
    "\n",
    "        # Track time in therapeutic range\n",
    "        if self.locals[\"infos\"][0][\"plasma_concentration\"] >= self.env.therapeutic_range[0] and \\\n",
    "                self.locals[\"infos\"][0][\"plasma_concentration\"] <= self.env.therapeutic_range[1]:\n",
    "            self.time_in_therapeutic_range += 1\n",
    "\n",
    "        # Log on every log_interval\n",
    "        if self.n_calls % self.log_interval == 0:\n",
    "            # Log policy loss, value loss, and entropy loss\n",
    "            policy_loss = self.locals[\"losses\"].get(\"policy_loss\", 0)\n",
    "            value_loss = self.locals[\"losses\"].get(\"value_loss\", 0)\n",
    "            entropy_loss = self.locals[\"losses\"].get(\"entropy_loss\", 0)\n",
    "\n",
    "            self.writer.add_scalar(\"Loss/Policy\", policy_loss, self.n_calls)\n",
    "            self.writer.add_scalar(\"Loss/Value\", value_loss, self.n_calls)\n",
    "            self.writer.add_scalar(\"Loss/Entropy\", entropy_loss, self.n_calls)\n",
    "            self.writer.add_scalar(\"Metrics/Time_in_Therapeutic_Range\", self.time_in_therapeutic_range, self.n_calls)\n",
    "\n",
    "        # If the episode ends, log the total reward for that episode\n",
    "        if self.locals[\"dones\"][0]:\n",
    "            self.episode_rewards.append(self.current_episode_reward)\n",
    "            self.current_episode_reward = 0  # Reset for next episode\n",
    "\n",
    "        return True"
   ],
   "id": "57b192c1548e09d4",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 5: Optimization of Hyperparameters",
   "id": "be7f3313f9c323c7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T23:20:21.022124Z",
     "start_time": "2024-12-03T23:20:21.014712Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def optimize_ppo(trial):\n",
    "    # Set up the environment\n",
    "    env = DummyVecEnv([lambda: IbuprofenEnv(normalize=True)])\n",
    "\n",
    "    # Hyperparameter tuning using Optuna\n",
    "    lr = trial.suggest_float(\"learning_rate\", 1e-5, 1e-3, log=True)\n",
    "    gamma = trial.suggest_float(\"gamma\", 0.90, 0.99)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 3, 10)\n",
    "    ent_coef = trial.suggest_float(\"ent_coef\", 1e-4, 1e-2, log=True)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 32, 512, step=32)\n",
    "    n_steps = trial.suggest_int(\"n_steps\", 64, 2048, step=64)\n",
    "    gae_lambda = trial.suggest_float(\"gae_lambda\", 0.8, 0.99)\n",
    "    clip_range = trial.suggest_float(\"clip_range\", 0.1, 0.3)\n",
    "\n",
    "    model = PPO(\n",
    "        \"MlpPolicy\",\n",
    "        env,\n",
    "        learning_rate=lr,\n",
    "        gamma=gamma,\n",
    "        n_epochs=n_epochs,\n",
    "        ent_coef=ent_coef,\n",
    "        batch_size=batch_size,\n",
    "        n_steps=n_steps,\n",
    "        gae_lambda=gae_lambda,\n",
    "        clip_range=clip_range,\n",
    "        verbose=0,\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    model.learn(total_timesteps=24000)\n",
    "\n",
    "    # Evaluate the model\n",
    "    rewards = []\n",
    "    for _ in range(100):\n",
    "        obs = env.reset()\n",
    "        total_reward = 0\n",
    "        done = False\n",
    "        while not done:\n",
    "            action, _ = model.predict(obs, deterministic=True)\n",
    "            obs, reward, done, _ = env.step(action)\n",
    "            total_reward += reward\n",
    "        rewards.append(total_reward)\n",
    "\n",
    "    return np.mean(rewards)\n"
   ],
   "id": "2094d26fa1dc2aaf",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 6: Perform Optimization",
   "id": "57fcaffecc3d1e80"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T23:48:52.836715Z",
     "start_time": "2024-12-03T23:20:21.086433Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Running the Optuna optimization\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(optimize_ppo, n_trials=100)\n",
    "\n",
    "# Extracting best hyperparameters\n",
    "best_params = study.best_params\n",
    "print(\"Best Parameters:\", best_params)"
   ],
   "id": "49841b9e9ff284f6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-03 23:20:21,088] A new study created in memory with name: no-name-a86dd5da-2e39-4682-8930-03861da90fc5\n",
      "/Users/xuenbei/miniconda3/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 96, but because the `RolloutBuffer` is of size `n_steps * n_envs = 832`, after every 8 untruncated mini-batches, there will be a truncated mini-batch of size 64\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=832 and n_envs=1)\n",
      "  warnings.warn(\n",
      "[I 2024-12-03 23:20:49,098] Trial 0 finished with value: -240.0 and parameters: {'learning_rate': 1.032587895743112e-05, 'gamma': 0.930133318656932, 'n_epochs': 6, 'ent_coef': 0.006661960318899696, 'batch_size': 96, 'n_steps': 832, 'gae_lambda': 0.9234313806855804, 'clip_range': 0.2596781596057674}. Best is trial 0 with value: -240.0.\n",
      "/Users/xuenbei/miniconda3/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 224, but because the `RolloutBuffer` is of size `n_steps * n_envs = 960`, after every 4 untruncated mini-batches, there will be a truncated mini-batch of size 64\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=960 and n_envs=1)\n",
      "  warnings.warn(\n",
      "[I 2024-12-03 23:21:09,921] Trial 1 finished with value: -240.0 and parameters: {'learning_rate': 0.00019340424619755764, 'gamma': 0.9313684450677775, 'n_epochs': 8, 'ent_coef': 0.0001407091492971411, 'batch_size': 224, 'n_steps': 960, 'gae_lambda': 0.8987620593371276, 'clip_range': 0.22854361856702}. Best is trial 0 with value: -240.0.\n",
      "[I 2024-12-03 23:21:28,678] Trial 2 finished with value: -240.0 and parameters: {'learning_rate': 0.00015297669530156018, 'gamma': 0.974878024185078, 'n_epochs': 8, 'ent_coef': 0.002978721830980986, 'batch_size': 256, 'n_steps': 1024, 'gae_lambda': 0.8487090083692916, 'clip_range': 0.18413596441760716}. Best is trial 0 with value: -240.0.\n",
      "/Users/xuenbei/miniconda3/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 128, but because the `RolloutBuffer` is of size `n_steps * n_envs = 1728`, after every 13 untruncated mini-batches, there will be a truncated mini-batch of size 64\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=1728 and n_envs=1)\n",
      "  warnings.warn(\n",
      "[I 2024-12-03 23:21:46,226] Trial 3 finished with value: -240.0 and parameters: {'learning_rate': 6.775993687537817e-05, 'gamma': 0.9098628677830648, 'n_epochs': 3, 'ent_coef': 0.0010698082911288994, 'batch_size': 128, 'n_steps': 1728, 'gae_lambda': 0.9232801379122642, 'clip_range': 0.2980621163958201}. Best is trial 0 with value: -240.0.\n",
      "/Users/xuenbei/miniconda3/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 256, but because the `RolloutBuffer` is of size `n_steps * n_envs = 384`, after every 1 untruncated mini-batches, there will be a truncated mini-batch of size 128\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=384 and n_envs=1)\n",
      "  warnings.warn(\n",
      "[I 2024-12-03 23:22:08,337] Trial 4 finished with value: -240.0 and parameters: {'learning_rate': 0.00014973753562959647, 'gamma': 0.9453482460333756, 'n_epochs': 4, 'ent_coef': 0.00010155063740077465, 'batch_size': 256, 'n_steps': 384, 'gae_lambda': 0.8442899406988993, 'clip_range': 0.11478851764411993}. Best is trial 0 with value: -240.0.\n",
      "/Users/xuenbei/miniconda3/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 288, but because the `RolloutBuffer` is of size `n_steps * n_envs = 1664`, after every 5 untruncated mini-batches, there will be a truncated mini-batch of size 224\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=1664 and n_envs=1)\n",
      "  warnings.warn(\n",
      "[I 2024-12-03 23:22:29,264] Trial 5 finished with value: 240.0 and parameters: {'learning_rate': 0.0008137948579639748, 'gamma': 0.9495267567320966, 'n_epochs': 9, 'ent_coef': 0.0013798549030065812, 'batch_size': 288, 'n_steps': 1664, 'gae_lambda': 0.8236677947525577, 'clip_range': 0.2963629220913797}. Best is trial 5 with value: 240.0.\n",
      "[I 2024-12-03 23:23:03,048] Trial 6 finished with value: 240.0 and parameters: {'learning_rate': 0.00015138626235893735, 'gamma': 0.9644955456789195, 'n_epochs': 8, 'ent_coef': 0.00013517713005906622, 'batch_size': 32, 'n_steps': 1856, 'gae_lambda': 0.9372224052064713, 'clip_range': 0.2516439248225699}. Best is trial 5 with value: 240.0.\n",
      "/Users/xuenbei/miniconda3/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 192, but because the `RolloutBuffer` is of size `n_steps * n_envs = 1600`, after every 8 untruncated mini-batches, there will be a truncated mini-batch of size 64\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=1600 and n_envs=1)\n",
      "  warnings.warn(\n",
      "[I 2024-12-03 23:23:21,405] Trial 7 finished with value: -240.0 and parameters: {'learning_rate': 1.9846663918589525e-05, 'gamma': 0.9424605468610774, 'n_epochs': 8, 'ent_coef': 0.002237737426594138, 'batch_size': 192, 'n_steps': 1600, 'gae_lambda': 0.849817345290258, 'clip_range': 0.11821426854733284}. Best is trial 5 with value: 240.0.\n",
      "/Users/xuenbei/miniconda3/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 384, but because the `RolloutBuffer` is of size `n_steps * n_envs = 512`, after every 1 untruncated mini-batches, there will be a truncated mini-batch of size 128\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=512 and n_envs=1)\n",
      "  warnings.warn(\n",
      "[I 2024-12-03 23:23:37,938] Trial 8 finished with value: 240.0 and parameters: {'learning_rate': 0.0008553903058473913, 'gamma': 0.9027992565585755, 'n_epochs': 8, 'ent_coef': 0.0011925401120420618, 'batch_size': 384, 'n_steps': 512, 'gae_lambda': 0.964858188157521, 'clip_range': 0.16794143913506143}. Best is trial 5 with value: 240.0.\n",
      "/Users/xuenbei/miniconda3/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 352, but because the `RolloutBuffer` is of size `n_steps * n_envs = 128`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 128\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=128 and n_envs=1)\n",
      "  warnings.warn(\n",
      "[I 2024-12-03 23:23:55,223] Trial 9 finished with value: 207.3175048828125 and parameters: {'learning_rate': 0.000505841761304093, 'gamma': 0.9057322832183745, 'n_epochs': 5, 'ent_coef': 0.0005512091426016114, 'batch_size': 352, 'n_steps': 128, 'gae_lambda': 0.9778073400890707, 'clip_range': 0.13579945545853706}. Best is trial 5 with value: 240.0.\n",
      "/Users/xuenbei/miniconda3/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 512, but because the `RolloutBuffer` is of size `n_steps * n_envs = 1408`, after every 2 untruncated mini-batches, there will be a truncated mini-batch of size 384\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=1408 and n_envs=1)\n",
      "  warnings.warn(\n",
      "[I 2024-12-03 23:24:10,450] Trial 10 finished with value: 240.0 and parameters: {'learning_rate': 0.0004320396304459312, 'gamma': 0.9894707260707689, 'n_epochs': 10, 'ent_coef': 0.0003954048512895622, 'batch_size': 512, 'n_steps': 1408, 'gae_lambda': 0.800778429469182, 'clip_range': 0.29779522283681936}. Best is trial 5 with value: 240.0.\n",
      "[I 2024-12-03 23:24:48,489] Trial 11 finished with value: 240.0 and parameters: {'learning_rate': 4.763691987003557e-05, 'gamma': 0.9607686348323418, 'n_epochs': 10, 'ent_coef': 0.00027122437872916194, 'batch_size': 32, 'n_steps': 1856, 'gae_lambda': 0.8053973273748444, 'clip_range': 0.24907225705676977}. Best is trial 5 with value: 240.0.\n",
      "[I 2024-12-03 23:25:03,840] Trial 12 finished with value: -240.0 and parameters: {'learning_rate': 0.00035409461968208516, 'gamma': 0.9605421057485479, 'n_epochs': 9, 'ent_coef': 0.0020640714414077556, 'batch_size': 352, 'n_steps': 1408, 'gae_lambda': 0.9463235217948514, 'clip_range': 0.27229935458786503}. Best is trial 5 with value: 240.0.\n",
      "/Users/xuenbei/miniconda3/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 448, but because the `RolloutBuffer` is of size `n_steps * n_envs = 2048`, after every 4 untruncated mini-batches, there will be a truncated mini-batch of size 256\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=2048 and n_envs=1)\n",
      "  warnings.warn(\n",
      "[I 2024-12-03 23:25:18,200] Trial 13 finished with value: 240.0 and parameters: {'learning_rate': 0.0008983993055786963, 'gamma': 0.9624924960528882, 'n_epochs': 7, 'ent_coef': 0.007686201046948386, 'batch_size': 448, 'n_steps': 2048, 'gae_lambda': 0.8779897494708875, 'clip_range': 0.23632098446114946}. Best is trial 5 with value: 240.0.\n",
      "/Users/xuenbei/miniconda3/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 160, but because the `RolloutBuffer` is of size `n_steps * n_envs = 1344`, after every 8 untruncated mini-batches, there will be a truncated mini-batch of size 64\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=1344 and n_envs=1)\n",
      "  warnings.warn(\n",
      "[I 2024-12-03 23:25:33,812] Trial 14 finished with value: -240.0 and parameters: {'learning_rate': 3.49489050324439e-05, 'gamma': 0.9760665747676903, 'n_epochs': 6, 'ent_coef': 0.0006610189671100684, 'batch_size': 160, 'n_steps': 1344, 'gae_lambda': 0.8900396855991981, 'clip_range': 0.2020229275490037}. Best is trial 5 with value: 240.0.\n",
      "[I 2024-12-03 23:26:07,363] Trial 15 finished with value: 207.3175048828125 and parameters: {'learning_rate': 0.00028019696559724845, 'gamma': 0.9479224413730035, 'n_epochs': 9, 'ent_coef': 0.00021292237583186586, 'batch_size': 32, 'n_steps': 2048, 'gae_lambda': 0.9330088061624212, 'clip_range': 0.2792813643809162}. Best is trial 5 with value: 240.0.\n",
      "[I 2024-12-03 23:26:21,457] Trial 16 finished with value: -240.0 and parameters: {'learning_rate': 8.282193416811904e-05, 'gamma': 0.9243547089436082, 'n_epochs': 7, 'ent_coef': 0.0040178753737400786, 'batch_size': 320, 'n_steps': 1600, 'gae_lambda': 0.8294217185512159, 'clip_range': 0.21809356413463088}. Best is trial 5 with value: 240.0.\n",
      "/Users/xuenbei/miniconda3/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 96, but because the `RolloutBuffer` is of size `n_steps * n_envs = 1856`, after every 19 untruncated mini-batches, there will be a truncated mini-batch of size 32\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=1856 and n_envs=1)\n",
      "  warnings.warn(\n",
      "[I 2024-12-03 23:26:40,142] Trial 17 finished with value: 240.0 and parameters: {'learning_rate': 0.0002417453209551816, 'gamma': 0.9713227497678941, 'n_epochs': 9, 'ent_coef': 0.001454535649827487, 'batch_size': 96, 'n_steps': 1856, 'gae_lambda': 0.8725389688665999, 'clip_range': 0.27550333139712707}. Best is trial 5 with value: 240.0.\n",
      "/Users/xuenbei/miniconda3/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 416, but because the `RolloutBuffer` is of size `n_steps * n_envs = 1216`, after every 2 untruncated mini-batches, there will be a truncated mini-batch of size 384\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=1216 and n_envs=1)\n",
      "  warnings.warn(\n",
      "[I 2024-12-03 23:26:55,965] Trial 18 finished with value: -240.0 and parameters: {'learning_rate': 0.0005627776344324643, 'gamma': 0.952767480696087, 'n_epochs': 10, 'ent_coef': 0.0006799658674216716, 'batch_size': 416, 'n_steps': 1216, 'gae_lambda': 0.9893195936373725, 'clip_range': 0.25138648907020705}. Best is trial 5 with value: 240.0.\n",
      "[I 2024-12-03 23:27:10,360] Trial 19 finished with value: -240.0 and parameters: {'learning_rate': 0.00013439987189184857, 'gamma': 0.9891072248101698, 'n_epochs': 7, 'ent_coef': 0.0003373426318013586, 'batch_size': 320, 'n_steps': 1600, 'gae_lambda': 0.8993720651032202, 'clip_range': 0.21253248983869727}. Best is trial 5 with value: 240.0.\n",
      "/Users/xuenbei/miniconda3/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 288, but because the `RolloutBuffer` is of size `n_steps * n_envs = 1856`, after every 6 untruncated mini-batches, there will be a truncated mini-batch of size 128\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=1856 and n_envs=1)\n",
      "  warnings.warn(\n",
      "[I 2024-12-03 23:27:25,873] Trial 20 finished with value: -240.0 and parameters: {'learning_rate': 2.82202011842589e-05, 'gamma': 0.9363069886027638, 'n_epochs': 9, 'ent_coef': 0.0001742237772058392, 'batch_size': 288, 'n_steps': 1856, 'gae_lambda': 0.954253732554116, 'clip_range': 0.2872657751729261}. Best is trial 5 with value: 240.0.\n",
      "/Users/xuenbei/miniconda3/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 416, but because the `RolloutBuffer` is of size `n_steps * n_envs = 640`, after every 1 untruncated mini-batches, there will be a truncated mini-batch of size 224\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=640 and n_envs=1)\n",
      "  warnings.warn(\n",
      "[I 2024-12-03 23:27:42,963] Trial 21 finished with value: 240.0 and parameters: {'learning_rate': 0.0009041756183618314, 'gamma': 0.9161122747418793, 'n_epochs': 8, 'ent_coef': 0.0011495515820639473, 'batch_size': 416, 'n_steps': 640, 'gae_lambda': 0.9601932427256256, 'clip_range': 0.17400144368239331}. Best is trial 5 with value: 240.0.\n",
      "/Users/xuenbei/miniconda3/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 384, but because the `RolloutBuffer` is of size `n_steps * n_envs = 640`, after every 1 untruncated mini-batches, there will be a truncated mini-batch of size 256\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=640 and n_envs=1)\n",
      "  warnings.warn(\n",
      "[I 2024-12-03 23:27:58,327] Trial 22 finished with value: 240.0 and parameters: {'learning_rate': 0.0006430231517783552, 'gamma': 0.9545200141474709, 'n_epochs': 8, 'ent_coef': 0.0016266738615150944, 'batch_size': 384, 'n_steps': 640, 'gae_lambda': 0.9697065300763728, 'clip_range': 0.164809521347946}. Best is trial 5 with value: 240.0.\n",
      "/Users/xuenbei/miniconda3/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 480, but because the `RolloutBuffer` is of size `n_steps * n_envs = 128`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 128\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=128 and n_envs=1)\n",
      "  warnings.warn(\n",
      "[I 2024-12-03 23:28:15,820] Trial 23 finished with value: 240.0 and parameters: {'learning_rate': 0.0009813985476731324, 'gamma': 0.9178779482670727, 'n_epochs': 9, 'ent_coef': 0.004153521569782053, 'batch_size': 480, 'n_steps': 128, 'gae_lambda': 0.9358337388660023, 'clip_range': 0.14668741312098849}. Best is trial 5 with value: 240.0.\n",
      "[I 2024-12-03 23:28:33,670] Trial 24 finished with value: 240.0 and parameters: {'learning_rate': 0.0005813206435888235, 'gamma': 0.9002229998280256, 'n_epochs': 7, 'ent_coef': 0.0007517499857951992, 'batch_size': 192, 'n_steps': 384, 'gae_lambda': 0.9143399112691417, 'clip_range': 0.189543937941957}. Best is trial 5 with value: 240.0.\n",
      "[I 2024-12-03 23:28:55,278] Trial 25 finished with value: -240.0 and parameters: {'learning_rate': 0.00036036874665927555, 'gamma': 0.9674932684997459, 'n_epochs': 6, 'ent_coef': 0.00043757564214297253, 'batch_size': 288, 'n_steps': 1152, 'gae_lambda': 0.9436528618199037, 'clip_range': 0.16335032803433586}. Best is trial 5 with value: 240.0.\n",
      "[I 2024-12-03 23:29:16,787] Trial 26 finished with value: 240.0 and parameters: {'learning_rate': 0.0007104329585468853, 'gamma': 0.9800072304722481, 'n_epochs': 8, 'ent_coef': 0.0008936143028488047, 'batch_size': 384, 'n_steps': 768, 'gae_lambda': 0.8211164363402944, 'clip_range': 0.2381431691535743}. Best is trial 5 with value: 240.0.\n",
      "/Users/xuenbei/miniconda3/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 320, but because the `RolloutBuffer` is of size `n_steps * n_envs = 384`, after every 1 untruncated mini-batches, there will be a truncated mini-batch of size 64\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=384 and n_envs=1)\n",
      "  warnings.warn(\n",
      "[I 2024-12-03 23:29:38,151] Trial 27 finished with value: 240.0 and parameters: {'learning_rate': 0.0002896873964714933, 'gamma': 0.9400990450168111, 'n_epochs': 10, 'ent_coef': 0.0014641715962531714, 'batch_size': 320, 'n_steps': 384, 'gae_lambda': 0.967749173375857, 'clip_range': 0.257845294236439}. Best is trial 5 with value: 240.0.\n",
      "/Users/xuenbei/miniconda3/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 224, but because the `RolloutBuffer` is of size `n_steps * n_envs = 1728`, after every 7 untruncated mini-batches, there will be a truncated mini-batch of size 160\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=1728 and n_envs=1)\n",
      "  warnings.warn(\n",
      "[I 2024-12-03 23:29:56,957] Trial 28 finished with value: -240.0 and parameters: {'learning_rate': 0.00010579158467286781, 'gamma': 0.9539578698304014, 'n_epochs': 9, 'ent_coef': 0.0027060981633760584, 'batch_size': 224, 'n_steps': 1728, 'gae_lambda': 0.8679866387825298, 'clip_range': 0.15274844048157193}. Best is trial 5 with value: 240.0.\n",
      "/Users/xuenbei/miniconda3/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 160, but because the `RolloutBuffer` is of size `n_steps * n_envs = 832`, after every 5 untruncated mini-batches, there will be a truncated mini-batch of size 32\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=832 and n_envs=1)\n",
      "  warnings.warn(\n",
      "[I 2024-12-03 23:30:12,758] Trial 29 finished with value: -240.0 and parameters: {'learning_rate': 1.2440939836380332e-05, 'gamma': 0.9319872375030008, 'n_epochs': 5, 'ent_coef': 0.004565900372922254, 'batch_size': 160, 'n_steps': 832, 'gae_lambda': 0.9130551993250794, 'clip_range': 0.2693264219790392}. Best is trial 5 with value: 240.0.\n",
      "[I 2024-12-03 23:30:33,382] Trial 30 finished with value: -240.0 and parameters: {'learning_rate': 4.9010493374357916e-05, 'gamma': 0.9264483281104713, 'n_epochs': 7, 'ent_coef': 0.0004877216234012842, 'batch_size': 64, 'n_steps': 1280, 'gae_lambda': 0.9829802719145535, 'clip_range': 0.20535369836966497}. Best is trial 5 with value: 240.0.\n",
      "[I 2024-12-03 23:30:50,449] Trial 31 finished with value: 240.0 and parameters: {'learning_rate': 0.0004236461377416618, 'gamma': 0.9897117004183712, 'n_epochs': 10, 'ent_coef': 0.00037734641469221983, 'batch_size': 512, 'n_steps': 1408, 'gae_lambda': 0.8065083191965123, 'clip_range': 0.2980349885936716}. Best is trial 5 with value: 240.0.\n",
      "[I 2024-12-03 23:31:11,083] Trial 32 finished with value: -240.0 and parameters: {'learning_rate': 0.00020191505329667916, 'gamma': 0.9818277192530076, 'n_epochs': 10, 'ent_coef': 0.00012845199835719026, 'batch_size': 512, 'n_steps': 1536, 'gae_lambda': 0.8193280565449574, 'clip_range': 0.28549968486752436}. Best is trial 5 with value: 240.0.\n",
      "/Users/xuenbei/miniconda3/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 448, but because the `RolloutBuffer` is of size `n_steps * n_envs = 1088`, after every 2 untruncated mini-batches, there will be a truncated mini-batch of size 192\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=1088 and n_envs=1)\n",
      "  warnings.warn(\n",
      "[I 2024-12-03 23:31:29,537] Trial 33 finished with value: 240.0 and parameters: {'learning_rate': 0.00043943386530316943, 'gamma': 0.9676250284372884, 'n_epochs': 9, 'ent_coef': 0.00023668066592842876, 'batch_size': 448, 'n_steps': 1088, 'gae_lambda': 0.8228173407442321, 'clip_range': 0.26425055304901574}. Best is trial 5 with value: 240.0.\n",
      "/Users/xuenbei/miniconda3/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 448, but because the `RolloutBuffer` is of size `n_steps * n_envs = 1728`, after every 3 untruncated mini-batches, there will be a truncated mini-batch of size 384\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=1728 and n_envs=1)\n",
      "  warnings.warn(\n",
      "[I 2024-12-03 23:31:49,550] Trial 34 finished with value: 240.0 and parameters: {'learning_rate': 0.0006459488761677188, 'gamma': 0.9366979253434604, 'n_epochs': 8, 'ent_coef': 0.0009945909851540962, 'batch_size': 448, 'n_steps': 1728, 'gae_lambda': 0.8025502829632328, 'clip_range': 0.2971485504806233}. Best is trial 5 with value: 240.0.\n",
      "/Users/xuenbei/miniconda3/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 256, but because the `RolloutBuffer` is of size `n_steps * n_envs = 1472`, after every 5 untruncated mini-batches, there will be a truncated mini-batch of size 192\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=1472 and n_envs=1)\n",
      "  warnings.warn(\n",
      "[I 2024-12-03 23:32:12,360] Trial 35 finished with value: 240.0 and parameters: {'learning_rate': 0.0007095474118123328, 'gamma': 0.9479658486127602, 'n_epochs': 10, 'ent_coef': 0.0001035952098724756, 'batch_size': 256, 'n_steps': 1472, 'gae_lambda': 0.8325898926915771, 'clip_range': 0.18497151820581295}. Best is trial 5 with value: 240.0.\n",
      "/Users/xuenbei/miniconda3/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 224, but because the `RolloutBuffer` is of size `n_steps * n_envs = 1920`, after every 8 untruncated mini-batches, there will be a truncated mini-batch of size 128\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=1920 and n_envs=1)\n",
      "  warnings.warn(\n",
      "[I 2024-12-03 23:32:33,076] Trial 36 finished with value: 207.3175048828125 and parameters: {'learning_rate': 0.00019899974044524816, 'gamma': 0.9839400356787167, 'n_epochs': 8, 'ent_coef': 0.0011923905862542307, 'batch_size': 224, 'n_steps': 1920, 'gae_lambda': 0.8389844798858167, 'clip_range': 0.22963590726525598}. Best is trial 5 with value: 240.0.\n",
      "[I 2024-12-03 23:32:48,337] Trial 37 finished with value: 207.3175048828125 and parameters: {'learning_rate': 0.00037514179739560875, 'gamma': 0.9728333074189743, 'n_epochs': 9, 'ent_coef': 0.0001759458575202389, 'batch_size': 480, 'n_steps': 960, 'gae_lambda': 0.8558639514950523, 'clip_range': 0.28698762511234993}. Best is trial 5 with value: 240.0.\n",
      "/Users/xuenbei/miniconda3/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 384, but because the `RolloutBuffer` is of size `n_steps * n_envs = 1664`, after every 4 untruncated mini-batches, there will be a truncated mini-batch of size 128\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=1664 and n_envs=1)\n",
      "  warnings.warn(\n",
      "[I 2024-12-03 23:33:01,803] Trial 38 finished with value: -240.0 and parameters: {'learning_rate': 0.00013376511973749432, 'gamma': 0.9573382654817639, 'n_epochs': 3, 'ent_coef': 0.00204168664271259, 'batch_size': 384, 'n_steps': 1664, 'gae_lambda': 0.8117133436118441, 'clip_range': 0.13038406184413148}. Best is trial 5 with value: 240.0.\n",
      "/Users/xuenbei/miniconda3/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 352, but because the `RolloutBuffer` is of size `n_steps * n_envs = 256`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 256\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=256 and n_envs=1)\n",
      "  warnings.warn(\n",
      "[I 2024-12-03 23:33:16,942] Trial 39 finished with value: 240.0 and parameters: {'learning_rate': 0.0008180680800566049, 'gamma': 0.948503123410129, 'n_epochs': 8, 'ent_coef': 0.00027978788628736314, 'batch_size': 352, 'n_steps': 256, 'gae_lambda': 0.9211030774665113, 'clip_range': 0.25335262476738846}. Best is trial 5 with value: 240.0.\n",
      "[I 2024-12-03 23:33:35,794] Trial 40 finished with value: 240.0 and parameters: {'learning_rate': 0.0005177148251934889, 'gamma': 0.964844973071192, 'n_epochs': 10, 'ent_coef': 0.0005721924866816139, 'batch_size': 128, 'n_steps': 1920, 'gae_lambda': 0.9052609722521424, 'clip_range': 0.24228969471421985}. Best is trial 5 with value: 240.0.\n",
      "[I 2024-12-03 23:34:09,267] Trial 41 finished with value: 240.0 and parameters: {'learning_rate': 4.747006031988731e-05, 'gamma': 0.959827431244281, 'n_epochs': 10, 'ent_coef': 0.0002916034478193963, 'batch_size': 32, 'n_steps': 1856, 'gae_lambda': 0.8153710519889885, 'clip_range': 0.24878668815399382}. Best is trial 5 with value: 240.0.\n",
      "[I 2024-12-03 23:34:31,080] Trial 42 finished with value: 240.0 and parameters: {'learning_rate': 6.216753777150444e-05, 'gamma': 0.9430872912230642, 'n_epochs': 9, 'ent_coef': 0.0001417743491885282, 'batch_size': 64, 'n_steps': 1728, 'gae_lambda': 0.8138450257092804, 'clip_range': 0.22291731611342125}. Best is trial 5 with value: 240.0.\n",
      "[I 2024-12-03 23:34:56,829] Trial 43 finished with value: 240.0 and parameters: {'learning_rate': 0.00010229248708703697, 'gamma': 0.9771784134320446, 'n_epochs': 10, 'ent_coef': 0.00022043624108886286, 'batch_size': 64, 'n_steps': 1984, 'gae_lambda': 0.830703626329739, 'clip_range': 0.262996195898617}. Best is trial 5 with value: 240.0.\n",
      "/Users/xuenbei/miniconda3/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 128, but because the `RolloutBuffer` is of size `n_steps * n_envs = 1472`, after every 11 untruncated mini-batches, there will be a truncated mini-batch of size 64\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=1472 and n_envs=1)\n",
      "  warnings.warn(\n",
      "[I 2024-12-03 23:35:15,275] Trial 44 finished with value: -240.0 and parameters: {'learning_rate': 2.160322607475106e-05, 'gamma': 0.9682894144314844, 'n_epochs': 9, 'ent_coef': 0.0001746975990320035, 'batch_size': 128, 'n_steps': 1472, 'gae_lambda': 0.8001608267681983, 'clip_range': 0.29862121109378786}. Best is trial 5 with value: 240.0.\n",
      "[I 2024-12-03 23:35:31,705] Trial 45 finished with value: -240.0 and parameters: {'learning_rate': 7.606794788649725e-05, 'gamma': 0.9630342233654892, 'n_epochs': 10, 'ent_coef': 0.0008972625904776397, 'batch_size': 224, 'n_steps': 1792, 'gae_lambda': 0.8618822590532438, 'clip_range': 0.28234641450242876}. Best is trial 5 with value: 240.0.\n",
      "/Users/xuenbei/miniconda3/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 96, but because the `RolloutBuffer` is of size `n_steps * n_envs = 1600`, after every 16 untruncated mini-batches, there will be a truncated mini-batch of size 64\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=1600 and n_envs=1)\n",
      "  warnings.warn(\n",
      "[I 2024-12-03 23:35:47,396] Trial 46 finished with value: -240.0 and parameters: {'learning_rate': 3.9308652950957514e-05, 'gamma': 0.949858365438363, 'n_epochs': 4, 'ent_coef': 0.0004086644280978844, 'batch_size': 96, 'n_steps': 1600, 'gae_lambda': 0.8812503689807726, 'clip_range': 0.19302880926040328}. Best is trial 5 with value: 240.0.\n",
      "[I 2024-12-03 23:36:16,211] Trial 47 finished with value: -240.0 and parameters: {'learning_rate': 0.00024880266869599393, 'gamma': 0.9581886622131252, 'n_epochs': 8, 'ent_coef': 0.0003096855364822186, 'batch_size': 32, 'n_steps': 2048, 'gae_lambda': 0.9533934981002347, 'clip_range': 0.10465390179601083}. Best is trial 5 with value: 240.0.\n",
      "/Users/xuenbei/miniconda3/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 416, but because the `RolloutBuffer` is of size `n_steps * n_envs = 1344`, after every 3 untruncated mini-batches, there will be a truncated mini-batch of size 96\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=1344 and n_envs=1)\n",
      "  warnings.warn(\n",
      "[I 2024-12-03 23:36:37,654] Trial 48 finished with value: 240.0 and parameters: {'learning_rate': 0.0008228472286441124, 'gamma': 0.9851336261242433, 'n_epochs': 9, 'ent_coef': 0.001691962384935933, 'batch_size': 416, 'n_steps': 1344, 'gae_lambda': 0.8482895311258487, 'clip_range': 0.27468136400909365}. Best is trial 5 with value: 240.0.\n",
      "/Users/xuenbei/miniconda3/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 160, but because the `RolloutBuffer` is of size `n_steps * n_envs = 1792`, after every 11 untruncated mini-batches, there will be a truncated mini-batch of size 32\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=1792 and n_envs=1)\n",
      "  warnings.warn(\n",
      "[I 2024-12-03 23:37:02,034] Trial 49 finished with value: 240.0 and parameters: {'learning_rate': 0.0001702628301149756, 'gamma': 0.9093679353337548, 'n_epochs': 7, 'ent_coef': 0.00013128840086556448, 'batch_size': 160, 'n_steps': 1792, 'gae_lambda': 0.807835971690895, 'clip_range': 0.20999229740505165}. Best is trial 5 with value: 240.0.\n",
      "/Users/xuenbei/miniconda3/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 352, but because the `RolloutBuffer` is of size `n_steps * n_envs = 1536`, after every 4 untruncated mini-batches, there will be a truncated mini-batch of size 128\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=1536 and n_envs=1)\n",
      "  warnings.warn(\n",
      "[I 2024-12-03 23:37:16,891] Trial 50 finished with value: 240.0 and parameters: {'learning_rate': 0.00047594904375084635, 'gamma': 0.9399254627021528, 'n_epochs': 9, 'ent_coef': 0.0007223153453979953, 'batch_size': 352, 'n_steps': 1536, 'gae_lambda': 0.8359055414343239, 'clip_range': 0.22972199620357903}. Best is trial 5 with value: 240.0.\n",
      "/Users/xuenbei/miniconda3/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 480, but because the `RolloutBuffer` is of size `n_steps * n_envs = 1984`, after every 4 untruncated mini-batches, there will be a truncated mini-batch of size 64\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=1984 and n_envs=1)\n",
      "  warnings.warn(\n",
      "[I 2024-12-03 23:37:34,359] Trial 51 finished with value: 240.0 and parameters: {'learning_rate': 0.0009580426160589316, 'gamma': 0.9628352698220656, 'n_epochs': 7, 'ent_coef': 0.005580890751864162, 'batch_size': 480, 'n_steps': 1984, 'gae_lambda': 0.8902632542329848, 'clip_range': 0.23925569927588042}. Best is trial 5 with value: 240.0.\n",
      "[I 2024-12-03 23:37:51,318] Trial 52 finished with value: 240.0 and parameters: {'learning_rate': 0.000774122173822724, 'gamma': 0.9517295976008733, 'n_epochs': 8, 'ent_coef': 0.002821519296762276, 'batch_size': 448, 'n_steps': 2048, 'gae_lambda': 0.9430052835488097, 'clip_range': 0.24663648555098525}. Best is trial 5 with value: 240.0.\n",
      "/Users/xuenbei/miniconda3/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 512, but because the `RolloutBuffer` is of size `n_steps * n_envs = 1920`, after every 3 untruncated mini-batches, there will be a truncated mini-batch of size 384\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=1920 and n_envs=1)\n",
      "  warnings.warn(\n",
      "[I 2024-12-03 23:38:04,463] Trial 53 finished with value: -240.0 and parameters: {'learning_rate': 0.0003119141798353608, 'gamma': 0.9715025543674817, 'n_epochs': 6, 'ent_coef': 0.008409174596266573, 'batch_size': 512, 'n_steps': 1920, 'gae_lambda': 0.8799156433341234, 'clip_range': 0.1769649417408718}. Best is trial 5 with value: 240.0.\n",
      "/Users/xuenbei/miniconda3/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 480, but because the `RolloutBuffer` is of size `n_steps * n_envs = 1792`, after every 3 untruncated mini-batches, there will be a truncated mini-batch of size 352\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=1792 and n_envs=1)\n",
      "  warnings.warn(\n",
      "[I 2024-12-03 23:38:18,700] Trial 54 finished with value: 207.3175048828125 and parameters: {'learning_rate': 0.0006248283002164351, 'gamma': 0.9563953492019454, 'n_epochs': 7, 'ent_coef': 0.0033306814342473454, 'batch_size': 480, 'n_steps': 1792, 'gae_lambda': 0.9276983634520697, 'clip_range': 0.1975471080110766}. Best is trial 5 with value: 240.0.\n",
      "/Users/xuenbei/miniconda3/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 448, but because the `RolloutBuffer` is of size `n_steps * n_envs = 1664`, after every 3 untruncated mini-batches, there will be a truncated mini-batch of size 320\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=1664 and n_envs=1)\n",
      "  warnings.warn(\n",
      "[I 2024-12-03 23:38:30,997] Trial 55 finished with value: 240.0 and parameters: {'learning_rate': 0.0009799762158206706, 'gamma': 0.9451616432253371, 'n_epochs': 7, 'ent_coef': 0.006506088584177481, 'batch_size': 448, 'n_steps': 1664, 'gae_lambda': 0.9725043305324599, 'clip_range': 0.26905708594170963}. Best is trial 5 with value: 240.0.\n",
      "/Users/xuenbei/miniconda3/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 416, but because the `RolloutBuffer` is of size `n_steps * n_envs = 576`, after every 1 untruncated mini-batches, there will be a truncated mini-batch of size 160\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=576 and n_envs=1)\n",
      "  warnings.warn(\n",
      "[I 2024-12-03 23:38:44,656] Trial 56 finished with value: 240.0 and parameters: {'learning_rate': 0.0005487169477634533, 'gamma': 0.9184533515946237, 'n_epochs': 8, 'ent_coef': 0.00943033249714615, 'batch_size': 416, 'n_steps': 576, 'gae_lambda': 0.8251427721065108, 'clip_range': 0.2906864340633422}. Best is trial 5 with value: 240.0.\n",
      "/Users/xuenbei/miniconda3/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 288, but because the `RolloutBuffer` is of size `n_steps * n_envs = 1984`, after every 6 untruncated mini-batches, there will be a truncated mini-batch of size 256\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=1984 and n_envs=1)\n",
      "  warnings.warn(\n",
      "[I 2024-12-03 23:38:58,059] Trial 57 finished with value: -240.0 and parameters: {'learning_rate': 6.330710649110033e-05, 'gamma': 0.9764884846874754, 'n_epochs': 8, 'ent_coef': 0.00024432329881130096, 'batch_size': 288, 'n_steps': 1984, 'gae_lambda': 0.9610749391638084, 'clip_range': 0.21860183609998884}. Best is trial 5 with value: 240.0.\n",
      "[I 2024-12-03 23:39:10,742] Trial 58 finished with value: -240.0 and parameters: {'learning_rate': 0.00012497336924778424, 'gamma': 0.9620182632812343, 'n_epochs': 9, 'ent_coef': 0.00056561087973333, 'batch_size': 384, 'n_steps': 1664, 'gae_lambda': 0.844204048971682, 'clip_range': 0.25665628018617914}. Best is trial 5 with value: 240.0.\n",
      "/Users/xuenbei/miniconda3/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 320, but because the `RolloutBuffer` is of size `n_steps * n_envs = 512`, after every 1 untruncated mini-batches, there will be a truncated mini-batch of size 192\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=512 and n_envs=1)\n",
      "  warnings.warn(\n",
      "[I 2024-12-03 23:39:25,986] Trial 59 finished with value: -240.0 and parameters: {'learning_rate': 2.8385703950486356e-05, 'gamma': 0.9327729790771013, 'n_epochs': 10, 'ent_coef': 0.00035580965080398634, 'batch_size': 320, 'n_steps': 512, 'gae_lambda': 0.9856828019568498, 'clip_range': 0.2772104238341712}. Best is trial 5 with value: 240.0.\n",
      "/Users/xuenbei/miniconda3/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 192, but because the `RolloutBuffer` is of size `n_steps * n_envs = 832`, after every 4 untruncated mini-batches, there will be a truncated mini-batch of size 64\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=832 and n_envs=1)\n",
      "  warnings.warn(\n",
      "[I 2024-12-03 23:39:37,323] Trial 60 finished with value: 240.0 and parameters: {'learning_rate': 0.0003883672199844879, 'gamma': 0.9001187348343461, 'n_epochs': 6, 'ent_coef': 0.0022214585323180407, 'batch_size': 192, 'n_steps': 832, 'gae_lambda': 0.8079510096375319, 'clip_range': 0.2909112033898495}. Best is trial 5 with value: 240.0.\n",
      "[I 2024-12-03 23:39:50,461] Trial 61 finished with value: 240.0 and parameters: {'learning_rate': 0.00023769554903628614, 'gamma': 0.9705160545427143, 'n_epochs': 9, 'ent_coef': 0.001487321233931064, 'batch_size': 96, 'n_steps': 1856, 'gae_lambda': 0.9006335451761471, 'clip_range': 0.2667744624618726}. Best is trial 5 with value: 240.0.\n",
      "[I 2024-12-03 23:40:05,952] Trial 62 finished with value: 240.0 and parameters: {'learning_rate': 0.00016345508071362495, 'gamma': 0.9664779496012965, 'n_epochs': 10, 'ent_coef': 0.001168323550056455, 'batch_size': 64, 'n_steps': 1920, 'gae_lambda': 0.8723685725266557, 'clip_range': 0.2757534224777123}. Best is trial 5 with value: 240.0.\n",
      "[I 2024-12-03 23:40:29,661] Trial 63 finished with value: 207.3175048828125 and parameters: {'learning_rate': 0.00030520832574584676, 'gamma': 0.9738815624143832, 'n_epochs': 9, 'ent_coef': 0.0008217491148195769, 'batch_size': 32, 'n_steps': 1792, 'gae_lambda': 0.8834558902562114, 'clip_range': 0.282091579739701}. Best is trial 5 with value: 240.0.\n",
      "[I 2024-12-03 23:40:44,220] Trial 64 finished with value: 240.0 and parameters: {'learning_rate': 0.00023847955058443117, 'gamma': 0.9788267477485163, 'n_epochs': 8, 'ent_coef': 0.0004699070409921813, 'batch_size': 64, 'n_steps': 1216, 'gae_lambda': 0.9346606099998686, 'clip_range': 0.2912041245742055}. Best is trial 5 with value: 240.0.\n",
      "/Users/xuenbei/miniconda3/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 96, but because the `RolloutBuffer` is of size `n_steps * n_envs = 64`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 64\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=64 and n_envs=1)\n",
      "  warnings.warn(\n",
      "[I 2024-12-03 23:41:02,310] Trial 65 finished with value: 240.0 and parameters: {'learning_rate': 0.0008030849292002646, 'gamma': 0.9543900509001614, 'n_epochs': 9, 'ent_coef': 0.0012969180953683861, 'batch_size': 96, 'n_steps': 64, 'gae_lambda': 0.8563162977664968, 'clip_range': 0.259621106392739}. Best is trial 5 with value: 240.0.\n",
      "[I 2024-12-03 23:41:27,342] Trial 66 finished with value: 240.0 and parameters: {'learning_rate': 0.0004676155078599184, 'gamma': 0.9863076025169895, 'n_epochs': 10, 'ent_coef': 0.00019704401580108465, 'batch_size': 32, 'n_steps': 1856, 'gae_lambda': 0.8695897854892733, 'clip_range': 0.2315321969808965}. Best is trial 5 with value: 240.0.\n",
      "/Users/xuenbei/miniconda3/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 256, but because the `RolloutBuffer` is of size `n_steps * n_envs = 960`, after every 3 untruncated mini-batches, there will be a truncated mini-batch of size 192\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=960 and n_envs=1)\n",
      "  warnings.warn(\n",
      "[I 2024-12-03 23:41:37,199] Trial 67 finished with value: -240.0 and parameters: {'learning_rate': 8.896646589938898e-05, 'gamma': 0.9594578061923251, 'n_epochs': 5, 'ent_coef': 0.001799365599009484, 'batch_size': 256, 'n_steps': 960, 'gae_lambda': 0.8915054011526788, 'clip_range': 0.24627598358945157}. Best is trial 5 with value: 240.0.\n",
      "/Users/xuenbei/miniconda3/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 416, but because the `RolloutBuffer` is of size `n_steps * n_envs = 2048`, after every 4 untruncated mini-batches, there will be a truncated mini-batch of size 384\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=2048 and n_envs=1)\n",
      "  warnings.warn(\n",
      "[I 2024-12-03 23:41:46,062] Trial 68 finished with value: 240.0 and parameters: {'learning_rate': 0.0006626217178620511, 'gamma': 0.9646577801504012, 'n_epochs': 7, 'ent_coef': 0.0001049715252218131, 'batch_size': 416, 'n_steps': 2048, 'gae_lambda': 0.8191062481828215, 'clip_range': 0.15401917343782498}. Best is trial 5 with value: 240.0.\n",
      "[I 2024-12-03 23:41:57,066] Trial 69 finished with value: -240.0 and parameters: {'learning_rate': 1.0985971159652434e-05, 'gamma': 0.9692147804080165, 'n_epochs': 10, 'ent_coef': 0.0009604686729452886, 'batch_size': 352, 'n_steps': 1536, 'gae_lambda': 0.910030447918044, 'clip_range': 0.2724270832376247}. Best is trial 5 with value: 240.0.\n",
      "/Users/xuenbei/miniconda3/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 512, but because the `RolloutBuffer` is of size `n_steps * n_envs = 256`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 256\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=256 and n_envs=1)\n",
      "  warnings.warn(\n",
      "[I 2024-12-03 23:42:09,324] Trial 70 finished with value: 240.0 and parameters: {'learning_rate': 0.0003394855213801636, 'gamma': 0.9518137436076046, 'n_epochs': 9, 'ent_coef': 0.002478225477590046, 'batch_size': 512, 'n_steps': 256, 'gae_lambda': 0.826347524436299, 'clip_range': 0.23590145101990004}. Best is trial 5 with value: 240.0.\n",
      "/Users/xuenbei/miniconda3/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 416, but because the `RolloutBuffer` is of size `n_steps * n_envs = 704`, after every 1 untruncated mini-batches, there will be a truncated mini-batch of size 288\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=704 and n_envs=1)\n",
      "  warnings.warn(\n",
      "[I 2024-12-03 23:42:20,202] Trial 71 finished with value: 240.0 and parameters: {'learning_rate': 0.0009374504625812828, 'gamma': 0.9067497047141271, 'n_epochs': 8, 'ent_coef': 0.0013577395546687204, 'batch_size': 416, 'n_steps': 704, 'gae_lambda': 0.9623976936936961, 'clip_range': 0.1650565794335867}. Best is trial 5 with value: 240.0.\n",
      "[I 2024-12-03 23:42:31,518] Trial 72 finished with value: 240.0 and parameters: {'learning_rate': 0.0008696815131294537, 'gamma': 0.9144324715556187, 'n_epochs': 8, 'ent_coef': 0.0006408420045808023, 'batch_size': 384, 'n_steps': 640, 'gae_lambda': 0.9767395754636198, 'clip_range': 0.17975363810082412}. Best is trial 5 with value: 240.0.\n",
      "[I 2024-12-03 23:42:41,028] Trial 73 finished with value: 207.3175048828125 and parameters: {'learning_rate': 0.0005838339452663915, 'gamma': 0.9047001698168942, 'n_epochs': 8, 'ent_coef': 0.001109603080861488, 'batch_size': 480, 'n_steps': 1984, 'gae_lambda': 0.9585468585562412, 'clip_range': 0.16817039281281043}. Best is trial 5 with value: 240.0.\n",
      "/Users/xuenbei/miniconda3/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 384, but because the `RolloutBuffer` is of size `n_steps * n_envs = 448`, after every 1 untruncated mini-batches, there will be a truncated mini-batch of size 64\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=448 and n_envs=1)\n",
      "  warnings.warn(\n",
      "[I 2024-12-03 23:42:59,661] Trial 74 finished with value: 240.0 and parameters: {'learning_rate': 0.0007219475464306414, 'gamma': 0.9031532775538267, 'n_epochs': 7, 'ent_coef': 0.003580994643357671, 'batch_size': 384, 'n_steps': 448, 'gae_lambda': 0.8018317181014355, 'clip_range': 0.1726796488407058}. Best is trial 5 with value: 240.0.\n",
      "/Users/xuenbei/miniconda3/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 448, but because the `RolloutBuffer` is of size `n_steps * n_envs = 320`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 320\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=320 and n_envs=1)\n",
      "  warnings.warn(\n",
      "[I 2024-12-03 23:43:13,040] Trial 75 finished with value: 240.0 and parameters: {'learning_rate': 0.00041749104549574463, 'gamma': 0.92213894852724, 'n_epochs': 9, 'ent_coef': 0.001928024263677405, 'batch_size': 448, 'n_steps': 320, 'gae_lambda': 0.9467638266097579, 'clip_range': 0.15374831277740303}. Best is trial 5 with value: 240.0.\n",
      "[I 2024-12-03 23:43:35,057] Trial 76 finished with value: 207.3175048828125 and parameters: {'learning_rate': 0.00011866899998145938, 'gamma': 0.9821041941624256, 'n_epochs': 9, 'ent_coef': 0.00014834271124627185, 'batch_size': 32, 'n_steps': 1664, 'gae_lambda': 0.9213015260084735, 'clip_range': 0.1470316783007518}. Best is trial 5 with value: 240.0.\n",
      "/Users/xuenbei/miniconda3/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 160, but because the `RolloutBuffer` is of size `n_steps * n_envs = 1728`, after every 10 untruncated mini-batches, there will be a truncated mini-batch of size 128\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=1728 and n_envs=1)\n",
      "  warnings.warn(\n",
      "[I 2024-12-03 23:43:45,552] Trial 77 finished with value: 207.3175048828125 and parameters: {'learning_rate': 0.00074024126984101, 'gamma': 0.9121720405408679, 'n_epochs': 8, 'ent_coef': 0.0015014645492690368, 'batch_size': 160, 'n_steps': 1728, 'gae_lambda': 0.9506986776028682, 'clip_range': 0.13083049375321862}. Best is trial 5 with value: 240.0.\n",
      "[I 2024-12-03 23:43:55,890] Trial 78 finished with value: 240.0 and parameters: {'learning_rate': 0.0005323271291595232, 'gamma': 0.9267350924660172, 'n_epochs': 10, 'ent_coef': 0.0008371470953021899, 'batch_size': 480, 'n_steps': 1920, 'gae_lambda': 0.9664365620656744, 'clip_range': 0.2963382730764272}. Best is trial 5 with value: 240.0.\n",
      "/Users/xuenbei/miniconda3/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 448, but because the `RolloutBuffer` is of size `n_steps * n_envs = 1856`, after every 4 untruncated mini-batches, there will be a truncated mini-batch of size 64\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=1856 and n_envs=1)\n",
      "  warnings.warn(\n",
      "[I 2024-12-03 23:44:05,169] Trial 79 finished with value: -240.0 and parameters: {'learning_rate': 0.0001932470027498867, 'gamma': 0.9559801626582943, 'n_epochs': 7, 'ent_coef': 0.0010389515450967659, 'batch_size': 448, 'n_steps': 1856, 'gae_lambda': 0.9785340729664795, 'clip_range': 0.16004852785308488}. Best is trial 5 with value: 240.0.\n",
      "[I 2024-12-03 23:44:24,556] Trial 80 finished with value: -240.0 and parameters: {'learning_rate': 1.6130412028538393e-05, 'gamma': 0.9608661787212189, 'n_epochs': 8, 'ent_coef': 0.00026633667822555676, 'batch_size': 64, 'n_steps': 1344, 'gae_lambda': 0.9377680281960422, 'clip_range': 0.2551628916803192}. Best is trial 5 with value: 240.0.\n",
      "[I 2024-12-03 23:44:43,260] Trial 81 finished with value: 240.0 and parameters: {'learning_rate': 0.0008711747970236595, 'gamma': 0.9653555825589007, 'n_epochs': 8, 'ent_coef': 0.0016905795523904164, 'batch_size': 416, 'n_steps': 704, 'gae_lambda': 0.9741447203370771, 'clip_range': 0.16007899023186695}. Best is trial 5 with value: 240.0.\n",
      "/Users/xuenbei/miniconda3/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 352, but because the `RolloutBuffer` is of size `n_steps * n_envs = 512`, after every 1 untruncated mini-batches, there will be a truncated mini-batch of size 160\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=512 and n_envs=1)\n",
      "  warnings.warn(\n",
      "[I 2024-12-03 23:45:03,348] Trial 82 finished with value: 240.0 and parameters: {'learning_rate': 0.0006391478455037372, 'gamma': 0.9469888892640592, 'n_epochs': 9, 'ent_coef': 0.0012759355203459488, 'batch_size': 352, 'n_steps': 512, 'gae_lambda': 0.9683192924936304, 'clip_range': 0.1879637457037735}. Best is trial 5 with value: 240.0.\n",
      "/Users/xuenbei/miniconda3/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 288, but because the `RolloutBuffer` is of size `n_steps * n_envs = 960`, after every 3 untruncated mini-batches, there will be a truncated mini-batch of size 96\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=960 and n_envs=1)\n",
      "  warnings.warn(\n",
      "[I 2024-12-03 23:45:19,573] Trial 83 finished with value: 240.0 and parameters: {'learning_rate': 0.0006843754211276015, 'gamma': 0.953374034111239, 'n_epochs': 8, 'ent_coef': 0.001570957539865081, 'batch_size': 288, 'n_steps': 960, 'gae_lambda': 0.8134559748643403, 'clip_range': 0.17141390759417183}. Best is trial 5 with value: 240.0.\n",
      "/Users/xuenbei/miniconda3/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 320, but because the `RolloutBuffer` is of size `n_steps * n_envs = 768`, after every 2 untruncated mini-batches, there will be a truncated mini-batch of size 128\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=768 and n_envs=1)\n",
      "  warnings.warn(\n",
      "[I 2024-12-03 23:45:30,439] Trial 84 finished with value: 240.0 and parameters: {'learning_rate': 0.0008737055176453458, 'gamma': 0.9497890579990687, 'n_epochs': 6, 'ent_coef': 0.0010777424502412636, 'batch_size': 320, 'n_steps': 768, 'gae_lambda': 0.8760096413123257, 'clip_range': 0.14572556530648081}. Best is trial 5 with value: 240.0.\n",
      "/Users/xuenbei/miniconda3/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 320, but because the `RolloutBuffer` is of size `n_steps * n_envs = 576`, after every 1 untruncated mini-batches, there will be a truncated mini-batch of size 256\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=576 and n_envs=1)\n",
      "  warnings.warn(\n",
      "[I 2024-12-03 23:45:42,302] Trial 85 finished with value: -240.0 and parameters: {'learning_rate': 0.0005969533250615897, 'gamma': 0.9575047615273564, 'n_epochs': 7, 'ent_coef': 0.004816694066749765, 'batch_size': 320, 'n_steps': 576, 'gae_lambda': 0.9823759538402996, 'clip_range': 0.2824344208932415}. Best is trial 5 with value: 240.0.\n",
      "/Users/xuenbei/miniconda3/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 128, but because the `RolloutBuffer` is of size `n_steps * n_envs = 448`, after every 3 untruncated mini-batches, there will be a truncated mini-batch of size 64\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=448 and n_envs=1)\n",
      "  warnings.warn(\n",
      "[I 2024-12-03 23:45:56,946] Trial 86 finished with value: 240.0 and parameters: {'learning_rate': 0.00014866131148242828, 'gamma': 0.9553812876238955, 'n_epochs': 8, 'ent_coef': 0.002389145290543331, 'batch_size': 128, 'n_steps': 448, 'gae_lambda': 0.9292602347879368, 'clip_range': 0.1805378364605962}. Best is trial 5 with value: 240.0.\n",
      "/Users/xuenbei/miniconda3/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 384, but because the `RolloutBuffer` is of size `n_steps * n_envs = 1088`, after every 2 untruncated mini-batches, there will be a truncated mini-batch of size 320\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=1088 and n_envs=1)\n",
      "  warnings.warn(\n",
      "[I 2024-12-03 23:46:07,812] Trial 87 finished with value: 240.0 and parameters: {'learning_rate': 0.0005103325216648139, 'gamma': 0.9635557278650748, 'n_epochs': 9, 'ent_coef': 0.00011523056669030744, 'batch_size': 384, 'n_steps': 1088, 'gae_lambda': 0.8858675025347711, 'clip_range': 0.26412789245389684}. Best is trial 5 with value: 240.0.\n",
      "/Users/xuenbei/miniconda3/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 96, but because the `RolloutBuffer` is of size `n_steps * n_envs = 896`, after every 9 untruncated mini-batches, there will be a truncated mini-batch of size 32\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=896 and n_envs=1)\n",
      "  warnings.warn(\n",
      "[I 2024-12-03 23:46:22,059] Trial 88 finished with value: 207.3175048828125 and parameters: {'learning_rate': 0.0007873908045734104, 'gamma': 0.9433046642548061, 'n_epochs': 10, 'ent_coef': 0.0007556870254384477, 'batch_size': 96, 'n_steps': 896, 'gae_lambda': 0.9581901716410066, 'clip_range': 0.2235822763200007}. Best is trial 5 with value: 240.0.\n",
      "/Users/xuenbei/miniconda3/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 448, but because the `RolloutBuffer` is of size `n_steps * n_envs = 1472`, after every 3 untruncated mini-batches, there will be a truncated mini-batch of size 128\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=1472 and n_envs=1)\n",
      "  warnings.warn(\n",
      "[I 2024-12-03 23:46:32,111] Trial 89 finished with value: 240.0 and parameters: {'learning_rate': 0.00026164206757377603, 'gamma': 0.9881734500041138, 'n_epochs': 8, 'ent_coef': 0.0006331877698461227, 'batch_size': 448, 'n_steps': 1472, 'gae_lambda': 0.8058362409462299, 'clip_range': 0.2941768282189604}. Best is trial 5 with value: 240.0.\n",
      "/Users/xuenbei/miniconda3/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 384, but because the `RolloutBuffer` is of size `n_steps * n_envs = 1728`, after every 4 untruncated mini-batches, there will be a truncated mini-batch of size 192\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=1728 and n_envs=1)\n",
      "  warnings.warn(\n",
      "[I 2024-12-03 23:46:43,703] Trial 90 finished with value: 240.0 and parameters: {'learning_rate': 0.000977739044664803, 'gamma': 0.9364397347753133, 'n_epochs': 10, 'ent_coef': 0.0001640823441287769, 'batch_size': 384, 'n_steps': 1728, 'gae_lambda': 0.8642948690271717, 'clip_range': 0.20420646871246764}. Best is trial 5 with value: 240.0.\n",
      "/Users/xuenbei/miniconda3/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 512, but because the `RolloutBuffer` is of size `n_steps * n_envs = 128`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 128\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=128 and n_envs=1)\n",
      "  warnings.warn(\n",
      "[I 2024-12-03 23:47:00,402] Trial 91 finished with value: 240.0 and parameters: {'learning_rate': 0.0009982017325078823, 'gamma': 0.918080402659296, 'n_epochs': 9, 'ent_coef': 0.006973472105299347, 'batch_size': 512, 'n_steps': 128, 'gae_lambda': 0.9508799301831804, 'clip_range': 0.13648397211817864}. Best is trial 5 with value: 240.0.\n",
      "/Users/xuenbei/miniconda3/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 480, but because the `RolloutBuffer` is of size `n_steps * n_envs = 768`, after every 1 untruncated mini-batches, there will be a truncated mini-batch of size 288\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=768 and n_envs=1)\n",
      "  warnings.warn(\n",
      "[I 2024-12-03 23:47:11,528] Trial 92 finished with value: 240.0 and parameters: {'learning_rate': 0.0007161816390100129, 'gamma': 0.9089325479233039, 'n_epochs': 9, 'ent_coef': 0.004660072625561354, 'batch_size': 480, 'n_steps': 768, 'gae_lambda': 0.9899003652819909, 'clip_range': 0.14146163819048757}. Best is trial 5 with value: 240.0.\n",
      "/Users/xuenbei/miniconda3/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 480, but because the `RolloutBuffer` is of size `n_steps * n_envs = 320`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 320\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=320 and n_envs=1)\n",
      "  warnings.warn(\n",
      "[I 2024-12-03 23:47:23,919] Trial 93 finished with value: 240.0 and parameters: {'learning_rate': 0.0008383514284657663, 'gamma': 0.9290193220576239, 'n_epochs': 9, 'ent_coef': 0.008158387398257388, 'batch_size': 480, 'n_steps': 320, 'gae_lambda': 0.9410712826958967, 'clip_range': 0.15784888371587882}. Best is trial 5 with value: 240.0.\n",
      "/Users/xuenbei/miniconda3/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 512, but because the `RolloutBuffer` is of size `n_steps * n_envs = 1792`, after every 3 untruncated mini-batches, there will be a truncated mini-batch of size 256\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=1792 and n_envs=1)\n",
      "  warnings.warn(\n",
      "[I 2024-12-03 23:47:34,335] Trial 94 finished with value: 207.3175048828125 and parameters: {'learning_rate': 0.0005910112107796124, 'gamma': 0.9169387239366731, 'n_epochs': 10, 'ent_coef': 0.0030808548422927417, 'batch_size': 512, 'n_steps': 1792, 'gae_lambda': 0.914104880934928, 'clip_range': 0.11744667872773698}. Best is trial 5 with value: 240.0.\n",
      "/Users/xuenbei/miniconda3/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 416, but because the `RolloutBuffer` is of size `n_steps * n_envs = 192`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 192\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=192 and n_envs=1)\n",
      "  warnings.warn(\n",
      "[I 2024-12-03 23:47:49,824] Trial 95 finished with value: 240.0 and parameters: {'learning_rate': 0.0007404739093848937, 'gamma': 0.9595831344229478, 'n_epochs': 8, 'ent_coef': 0.005783300584559213, 'batch_size': 416, 'n_steps': 192, 'gae_lambda': 0.969574226573785, 'clip_range': 0.2503837926383329}. Best is trial 5 with value: 240.0.\n",
      "/Users/xuenbei/miniconda3/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 256, but because the `RolloutBuffer` is of size `n_steps * n_envs = 1984`, after every 7 untruncated mini-batches, there will be a truncated mini-batch of size 192\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=1984 and n_envs=1)\n",
      "  warnings.warn(\n",
      "[I 2024-12-03 23:48:02,717] Trial 96 finished with value: 240.0 and parameters: {'learning_rate': 0.0004897704854130617, 'gamma': 0.9218340712808355, 'n_epochs': 8, 'ent_coef': 0.0013828678816235908, 'batch_size': 256, 'n_steps': 1984, 'gae_lambda': 0.9029635034621808, 'clip_range': 0.2432427386980132}. Best is trial 5 with value: 240.0.\n",
      "/Users/xuenbei/miniconda3/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 448, but because the `RolloutBuffer` is of size `n_steps * n_envs = 64`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 64\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=64 and n_envs=1)\n",
      "  warnings.warn(\n",
      "[I 2024-12-03 23:48:21,083] Trial 97 finished with value: 240.0 and parameters: {'learning_rate': 0.0009141078366494295, 'gamma': 0.9709206851617547, 'n_epochs': 9, 'ent_coef': 0.0039924888649471866, 'batch_size': 448, 'n_steps': 64, 'gae_lambda': 0.9628162207195206, 'clip_range': 0.2878954872902215}. Best is trial 5 with value: 240.0.\n",
      "[I 2024-12-03 23:48:41,505] Trial 98 finished with value: 240.0 and parameters: {'learning_rate': 4.947087081978524e-05, 'gamma': 0.9339083055507041, 'n_epochs': 7, 'ent_coef': 0.0003201743534028771, 'batch_size': 32, 'n_steps': 640, 'gae_lambda': 0.811033164366762, 'clip_range': 0.1943011970255687}. Best is trial 5 with value: 240.0.\n",
      "[I 2024-12-03 23:48:52,794] Trial 99 finished with value: 240.0 and parameters: {'learning_rate': 0.0006547692547103188, 'gamma': 0.9412425663491635, 'n_epochs': 10, 'ent_coef': 0.0012329592545118986, 'batch_size': 512, 'n_steps': 2048, 'gae_lambda': 0.8164553466058879, 'clip_range': 0.2347178523849907}. Best is trial 5 with value: 240.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate': 0.0008137948579639748, 'gamma': 0.9495267567320966, 'n_epochs': 9, 'ent_coef': 0.0013798549030065812, 'batch_size': 288, 'n_steps': 1664, 'gae_lambda': 0.8236677947525577, 'clip_range': 0.2963629220913797}\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 7: Train the agent with best hyperparameters",
   "id": "72dd4900ad7d6581"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T23:48:55.125546Z",
     "start_time": "2024-12-03T23:48:54.015556Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set up environment\n",
    "env = DummyVecEnv([lambda: IbuprofenEnv(normalize=True)])\n",
    "\n",
    "best_params = study.best_params\n",
    "\n",
    "# Set up PPO model with hyperparameters\n",
    "final_model = PPO(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    learning_rate=best_params[\"learning_rate\"],\n",
    "    gamma=best_params[\"gamma\"],\n",
    "    n_epochs=best_params[\"n_epochs\"],\n",
    "    ent_coef=best_params[\"ent_coef\"],\n",
    "    batch_size=best_params[\"batch_size\"],\n",
    "    n_steps=best_params[\"n_steps\"],\n",
    "    gae_lambda=best_params[\"gae_lambda\"],\n",
    "    clip_range=best_params[\"clip_range\"],\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "# Instantiate the custom callback\n",
    "callback = CustomLoggingCallback()\n",
    "\n",
    "# Train the model with the custom callback\n",
    "final_model.learn(total_timesteps=1000, callback=callback)"
   ],
   "id": "2aa797063822d9c3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "CustomLoggingCallback.__init__() missing 1 required positional argument: 'writer'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 20\u001B[0m\n\u001B[1;32m      5\u001B[0m final_model \u001B[38;5;241m=\u001B[39m PPO(\n\u001B[1;32m      6\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMlpPolicy\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      7\u001B[0m     env,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     16\u001B[0m     verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m     17\u001B[0m )\n\u001B[1;32m     19\u001B[0m \u001B[38;5;66;03m# Instantiate the custom callback\u001B[39;00m\n\u001B[0;32m---> 20\u001B[0m callback \u001B[38;5;241m=\u001B[39m CustomLoggingCallback()\n\u001B[1;32m     22\u001B[0m \u001B[38;5;66;03m# Train the model with the custom callback\u001B[39;00m\n\u001B[1;32m     23\u001B[0m final_model\u001B[38;5;241m.\u001B[39mlearn(total_timesteps\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1000\u001B[39m, callback\u001B[38;5;241m=\u001B[39mcallback)\n",
      "\u001B[0;31mTypeError\u001B[0m: CustomLoggingCallback.__init__() missing 1 required positional argument: 'writer'"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 8: Plot training and evaluation results",
   "id": "e1e085b64b0459c6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot the loss curves\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(callback.policy_losses, label='Policy Loss')\n",
    "plt.title('Policy Loss')\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid()"
   ],
   "id": "7ef967d7f844ced4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 9: Evaluation ",
   "id": "cbe523aee9e0de66"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(callback.value_losses, label='Value Loss', color='orange')\n",
    "plt.title('Value Loss')\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid()\n",
    "plt.show()\n"
   ],
   "id": "ad892a726e9e3fd3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(callback.entropy_losses, label='Entropy Loss', color='green')\n",
    "plt.title('Entropy Loss')\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid()\n"
   ],
   "id": "8b7052755bf57c77",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 10: Visualize Optuna Results",
   "id": "1402a7777e0e83af"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "optuna.visualization.plot_optimization_history(study).show()\n",
   "id": "c429bb5176d812e6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "optuna.visualization.plot_param_importances(study).show()",
   "id": "332f36110752f946",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "other visualization",
   "id": "b4936ddabcd70b77"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "8c953cb47a8c055d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "therapeutic_range_times = []\n",
    "\n",
    "for trajectory in plasma_concentration_trajectories:\n",
    "    time_in_range = sum(env.therapeutic_range[0] <= c <= env.therapeutic_range[1] for c in trajectory)\n",
    "    therapeutic_range_times.append(time_in_range / len(trajectory))\n",
    "\n",
    "avg_time_in_therapeutic_range = np.mean(therapeutic_range_times)\n",
    "print(f\"Average Time in Therapeutic Range: {avg_time_in_therapeutic_range * 100:.2f}%\")\n"
   ],
   "id": "ae3116e45678a73",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "toxic_level_exceedances = sum(c > 100 for trajectory in plasma_concentration_trajectories for c in trajectory)\n",
    "print(f\"Toxic Level Exceedances Across All Episodes: {toxic_level_exceedances}\")\n",
    "\n",
    "survival_rate = sum(1 for trajectory in plasma_concentration_trajectories if max(trajectory) <= 100) / len(plasma_concentration_trajectories)\n",
    "print(f\"Survival Rate: {survival_rate * 100:.2f}%\")"
   ],
   "id": "4ef4ac98607ffdc1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "87e230953b20bd5b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(plasma_concentration_trajectories, aspect='auto', cmap='viridis', interpolation='nearest')\n",
    "plt.colorbar(label=\"Plasma Concentration (mg/L)\")\n",
    "plt.xlabel(\"Time Steps\")\n",
    "plt.ylabel(\"Episode\")\n",
    "plt.title(\"Plasma Concentration Heatmap Across Episodes\")\n",
    "plt.show()\n"
   ],
   "id": "7eb22cc5f4f3b8bc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "cumulative_rewards = np.cumsum(reward_history)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(cumulative_rewards)\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Cumulative Reward\")\n",
    "plt.title(\"Cumulative Reward Trend\")\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "id": "6ba5c740ce8c8ac3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "action_rewards = {a: [] for a in range(env.action_space.n)}\n",
    "\n",
    "for trajectory, rewards in zip(plasma_concentration_trajectories, evaluation_rewards):\n",
    "    for action, reward in zip(trajectory, rewards):\n",
    "        action_rewards[action].append(reward)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for action, rewards in action_rewards.items():\n",
    "    plt.hist(rewards, bins=30, alpha=0.6, label=f\"Action {action}\")\n",
    "plt.xlabel(\"Reward\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Reward Distribution Per Action\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "id": "5acc5697a29977be",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#optimal policy evaluation\n",
    "action_frequencies = [np.argmax(agent.policy(torch.tensor(state, dtype=torch.float32).unsqueeze(0)).detach().numpy())\n",
    "                      for state in states]\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(action_frequencies, bins=env.action_space.n, alpha=0.7)\n",
    "plt.xlabel(\"Action\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Action Selection Frequency in Evaluation\")\n",
    "plt.grid()\n",
    "plt.show()\n"
   ],
   "id": "9f36db9c73a2498f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#learning stability\n",
    "rolling_avg_rewards = np.convolve(reward_history, np.ones(50)/50, mode='valid')\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(rolling_avg_rewards)\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Rolling Average Reward\")\n",
    "plt.title(\"Learning Stability: Rolling Average of Rewards\")\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "id": "184c10b4a83faf0f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
